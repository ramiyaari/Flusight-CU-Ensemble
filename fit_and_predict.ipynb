{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from darts_models import *\n",
    "from historical_mean_model import *\n",
    "from historical_drift_model import *\n",
    "from SIR_EAKF_model import *\n",
    "from SIR_AH_EAKF_model import *\n",
    "from peak_predictions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiyear = 2024\n",
    "epiweek = 50 \n",
    "ref_date = epiweek_to_dates(epiyear, epiweek).enddate() #Saturday at the end of epiweek\n",
    "\n",
    "data_dir = './data/'\n",
    "results_dir = './results/'\n",
    "figures_dir = './figures/' \n",
    "\n",
    "locations_fname = data_dir +\"locations.csv\"\n",
    "locations = pd.read_csv(locations_fname)\n",
    "loc_name2abbr = dict(zip(locations['location_name'], locations['abbreviation']))\n",
    "locations = locations.set_index('abbreviation')\n",
    "states = locations.index.values\n",
    "# states = np.array([\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DE\", \"DC\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \n",
    "#           \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \n",
    "#           \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"PR\", \"US\"])\n",
    "num_states = len(states)\n",
    "\n",
    "populations_fname = data_dir +\"populations.csv\"\n",
    "populations = pd.read_csv(populations_fname)\n",
    "# df_pop = generate_pop_per_week(states, populations)\n",
    "\n",
    "AH_daily, df_AH = read_AH(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_format = True\n",
    "download_hosp=False\n",
    "fix_partial_reporting=False\n",
    "fix_outliers=False\n",
    "df_hosp = read_hosp_incidence_data(data_dir, epiyear, epiweek, states, \n",
    "                                   new_format=new_format, download=download_hosp,\n",
    "                                   fix_partial_reporting=fix_partial_reporting, \n",
    "                                   fix_outliers=fix_outliers,\n",
    "                                   plot=False)\n",
    "\n",
    "df_ili = read_ili_incidence_data(data_dir, epiyear, epiweek, states, df_hosp, \n",
    "                                 smooth=False, scale=True, plot=False)\n",
    "\n",
    "plot_hosp_with_ili = False\n",
    "if(plot_hosp_with_ili):\n",
    "    fig, axs = plt.subplots(nrows=num_states, ncols=1, figsize=(7, 2 * num_states), sharex=True)\n",
    "    for i, state in enumerate(states):\n",
    "        ax = axs[i] if num_states > 1 else axs  # Handle single subplot case\n",
    "        ax.plot(df_hosp['date'], df_hosp[state], label='Hospitalizations', color='blue')\n",
    "        ax.plot(df_ili['date'], df_ili[state], label='Scaled ILI', color='red')\n",
    "        ax.set_title(f\"{state} - Hospitalizations vs. ILI (scaled)\")\n",
    "        ax.set_ylabel(\"Cases\")\n",
    "        ax.legend()\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_epiyear = 2022\n",
    "switch_epiweek = 26\n",
    "switch_date = pd.to_datetime(epiweek_to_dates(switch_epiyear, switch_epiweek).enddate())\n",
    "\n",
    "df1 = df_ili[df_ili.date < switch_date]\n",
    "df2 = df_hosp[(df_hosp.date >= switch_date)]\n",
    "df_hosp_ex = pd.concat([df1, df2]).reset_index()\n",
    "\n",
    "hosp_ex_start_date = pd.to_datetime('2010-10-09', format=\"%Y-%m-%d\")\n",
    "df_hosp_ex = df_hosp_ex[df_hosp_ex['date']>=hosp_ex_start_date]\n",
    "df_hosp_ex[states] = df_hosp_ex[states].fillna(0)\n",
    "# na_counts = df_hosp_ex[states].isna().sum()\n",
    "# na_counts\n",
    "\n",
    "df_hosp_ex_long = pd.melt(df_hosp_ex,id_vars=['date','year','week'],value_vars=df_hosp_ex.columns[3:],var_name='state',value_name='cases')\n",
    "plot_hosp_ex = False\n",
    "if(plot_hosp_ex):\n",
    "    g = sns.FacetGrid(df_hosp_ex_long, col=\"state\", col_wrap=5, hue=\"state\", sharey=False, sharex=True, height=3, aspect=1.33)\n",
    "    g.map(sns.lineplot, \"date\", \"cases\")\n",
    "    [plt.setp(ax.get_xticklabels(), rotation=90) for ax in g.axes.flat]\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "alpha_vals = [0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 1]\n",
    "quantiles = np.append(np.append([0.01,0.025],np.arange(0.05,0.95+0.05,0.050)),[0.975,0.99])\n",
    "weeks_to_predict = 4\n",
    "\n",
    "past_weeks = 0 # Set this to produce past weeks forecasts\n",
    "ref_dates = [pd.Timestamp(ref_date) + timedelta(weeks=w) for w in range(-past_weeks,1)]\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(230098)\n",
    "torch.manual_seed(42095703)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "darts_local_models, darts_global_models = get_darts_models(quantiles)\n",
    "\n",
    "sir_eakf_model = \"SIR-EAKF\"\n",
    "his_drift_model = \"historical_drift\"\n",
    "his_mean_model = \"historical_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate pred using sir_eakf/sir_ah_eakf model\n",
    "use_AH = False\n",
    "sir_eakf_start_date = pd.to_datetime('2024-09-14', format=\"%Y-%m-%d\")\n",
    "for ref_date1 in ref_dates:\n",
    "    dat_changerate_ref = df_hosp_ex[df_hosp_ex.date==ref_date1-timedelta(weeks=1)]\n",
    "    if(use_AH):\n",
    "        generate_sir_ah_eakf_pred(df_hosp_ex, sir_eakf_start_date, ref_date1, weeks_to_predict, \n",
    "                                locations, AH_daily, quantiles, num_samples, \n",
    "                                dat_changerate_ref, results_dir, model_desc=sir_eakf_model)\n",
    "    else:\n",
    "        generate_sir_eakf_pred(df_hosp_ex, sir_eakf_start_date, ref_date1, weeks_to_predict, \n",
    "                           locations, quantiles, num_samples, \n",
    "                           dat_changerate_ref, results_dir, model_desc=sir_eakf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate pred using historical drift model\n",
    "epiweek_window = 1\n",
    "for ref_date1 in ref_dates:\n",
    "    dat_changerate_ref = df_hosp_ex[df_hosp_ex.date==ref_date1-timedelta(weeks=1)]\n",
    "    generate_historical_drift_pred(df_hosp_ex, ref_date1, weeks_to_predict, locations, quantiles, num_samples, epiweek_window,\n",
    "                                   dat_changerate_ref, results_dir, model_desc=his_drift_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate pred using historical mean model\n",
    "df_his_pred = generate_historical_mean_pred(df_hosp_ex,states,quantiles,plot=False)\n",
    "for ref_date1 in ref_dates:\n",
    "    df_his = save_historical_mean_pred_results_to_file(df_his_pred, ref_date1, weeks_to_predict, locations, \n",
    "                                                       quantiles, results_dir, model_desc=his_mean_model)\n",
    "\n",
    "# df_his_pred_mean = df_his_pred.pivot(index='date', columns='state', values='mean').reset_index()\n",
    "# To use as covariate we need to continue this forward up to max horizon\n",
    "# for i in range(1,5):\n",
    "#     next = pd.Timestamp(epiweek_to_dates(epiyear, epiweek+i).enddate())\n",
    "#     next_last_year = pd.Timestamp(epiweek_to_dates(epiyear-1, epiweek+i).enddate())\n",
    "#     next_last_year_vals = df_his_pred_mean[df_his_pred_mean['date']==next_last_year].values\n",
    "#     df_his_pred_mean.loc[len(df_his_pred_mean)] = [next] + next_last_year_vals[0,1:].tolist()\n",
    "# df_his_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_lab_col = 'percent_positive'\n",
    "df_lab = read_lab_selected_data(data_dir, epiyear, epiweek, states, loc_name2abbr, sel_lab_col, plot=False)\n",
    "#add missing past values\n",
    "missing_dates = df_hosp_ex[~df_hosp_ex['date'].isin(df_lab['date'])]\n",
    "missing_dates_only = missing_dates[['date']].copy()\n",
    "for col in df_lab.columns:\n",
    "    if col != 'date':\n",
    "        missing_dates_only[col] = pd.NA\n",
    "df_lab = pd.concat([df_lab, missing_dates_only], ignore_index=True)\n",
    "df_lab = df_lab.sort_values(by='date').reset_index(drop=True)\n",
    "# To use as covariate we need to continue this forward up to max horizon\n",
    "for w in range(0,weeks_to_predict):\n",
    "    next_date = pd.Timestamp(ref_date) + timedelta(weeks=w)\n",
    "    df_lab.loc[len(df_lab)] = [next_date] + [pd.NA for s in range(num_states)]\n",
    "#     next_date = pd.Timestamp(epiweek_to_dates(epiyear, epiweek+w).enddate())\n",
    "#     next_last_year = pd.Timestamp(epiweek_to_dates(epiyear-1, epiweek+w).enddate())\n",
    "#     next_last_year_vals = df_lab[df_lab['date']==next_last_year].values\n",
    "#     df_lab.loc[len(df_lab)] = [next_date] + next_last_year_vals[0,1:].tolist()\n",
    "\n",
    "#Set to 0 values for states with missing lab for now\n",
    "df_lab['RI'] = 0 #pd.NA\n",
    "df_lab['PR'] = 0 #pd.NA\n",
    "df_lab['DC'] = 0 #pd.NA\n",
    "df_lab['NJ'] = 0 #pd.NA\n",
    "df_lab['NH'] = 0 #pd.NA\n",
    "df_lab['NV'] = 0 #pd.NA\n",
    "df_lab['AK'] = 0 #pd.NA\n",
    "df_lab['DE'] = 0 #pd.NA\n",
    "df_lab['UT'] = 0 #pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fit and predict darts models\n",
    "\n",
    "fit_single_local_model=False  #fit one model to all states for local models\n",
    "\n",
    "df_past_covar = None\n",
    "df_future_covar = None\n",
    "use_lab_covar = True\n",
    "use_ah_covar = True\n",
    "if(use_lab_covar):\n",
    "    df_past_covar = df_lab\n",
    "if(use_ah_covar):\n",
    "    df_future_covar = df_AH\n",
    "    # darts_local_models = {str(model_name) + '_AH': model for model_name, model in darts_local_models.items()}\n",
    "    # darts_global_models = {str(model_name) + '_AH': model for model_name, model in darts_global_models.items()}\n",
    "# else:\n",
    "#     darts_local_models = {str(model_name) + '_NoCov': model for model_name, model in darts_local_models.items()}\n",
    "#     darts_global_models = {str(model_name) + '_NoCov': model for model_name, model in darts_global_models.items()}\n",
    "\n",
    "for model_desc in darts_local_models:\n",
    "    print(\"-----------Model: {}-----------\".format(model_desc))\n",
    "    model = darts_local_models[model_desc]\n",
    "    for ref_date1 in ref_dates:\n",
    "        pred_start_date = ref_date1 \n",
    "        model = model.untrained_model()\n",
    "        pred = fit_and_predict_univariate(df_hosp_ex, states, model, model_desc, \n",
    "                                          pred_start_date, weeks_to_predict, num_samples, \n",
    "                                          fit_single_local_model, \n",
    "                                          df_past_covar, df_future_covar)\n",
    "        dat_changerate_ref = df_hosp_ex[df_hosp_ex.date==ref_date1-timedelta(weeks=1)]\n",
    "        save_darts_pred_results_to_file(pred, ref_date1, weeks_to_predict, locations, quantiles,\n",
    "                                        dat_changerate_ref, results_dir, model_desc)\n",
    "\n",
    "for model_desc in darts_global_models:\n",
    "    print(\"-----------Model: {}-----------\".format(model_desc))\n",
    "    model = darts_global_models[model_desc]\n",
    "    for ref_date1 in ref_dates:\n",
    "        pred_start_date = ref_date1 \n",
    "        model = model.untrained_model()\n",
    "        pred = fit_and_predict_multivariate(df_hosp_ex, states, model, model_desc, \n",
    "                                            pred_start_date, weeks_to_predict, num_samples,\n",
    "                                            df_past_covar, df_future_covar)\n",
    "        dat_changerate_ref = df_hosp_ex[df_hosp_ex.date==ref_date1-timedelta(weeks=1)]\n",
    "        save_darts_pred_results_to_file(pred, ref_date1, weeks_to_predict, locations, quantiles,\n",
    "                                        dat_changerate_ref, results_dir, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_and_plot_models(models, plot=True):\n",
    "    df_metrics_all = pd.DataFrame({\n",
    "        'location': pd.Series(dtype='str'),\n",
    "        'model': pd.Series(dtype='str'),\n",
    "        'horizon': pd.Series(dtype='int'),\n",
    "        'target_date': pd.Series(dtype='str'),\n",
    "        'metric': pd.Series(dtype='str'),\n",
    "        'value': pd.Series(dtype='float')\n",
    "    })\n",
    "    for model in models:\n",
    "        print(\"-----------Loading model: {}-----------\".format(model))\n",
    "        df_results = load_pred_result_files(results_dir, model, locations)\n",
    "        df_results = df_results[df_results['target'] == 'wk inc flu hosp']\n",
    "        print(\"-----------Calculating metrics for model: {}-----------\".format(model))\n",
    "        for loc_abbr in locations.index:\n",
    "            df_metrics = calc_and_plot_pred_results_fit(df_results, df_hosp_ex, locations, loc_abbr,  \n",
    "                                                        alpha_vals, figures_dir, model, plot=plot)\n",
    "            df_metrics_all = pd.concat([df_metrics_all, df_metrics], ignore_index=True) \n",
    "    return df_metrics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = list(darts_local_models.keys()) +\n",
    "                  list(darts_global_models.keys()) +\n",
    "                  [sir_eakf_model, his_drift_model]\n",
    "\n",
    "ensemble_dict = {}\n",
    "# load models predictions\n",
    "for model in ensemble_models:\n",
    "    print(\"-----------Loading model: {}-----------\".format(model))\n",
    "    df_results = load_pred_result_files(results_dir, model, locations)\n",
    "    ensemble_dict[model] = df_results\n",
    "\n",
    "ensemble_name = 'CU_Ensemble'\n",
    "use_weighted_ensemble = True\n",
    "if(use_weighted_ensemble):\n",
    "    df_metrics = calc_and_plot_models(ensemble_models,plot=False)\n",
    "    df_weights = generate_pred_weights(ensemble_dict, df_metrics, locations)\n",
    "    print(\"-----------Generating weighted ensemble: {}-----------\".format(ensemble_name))\n",
    "    generate_weighted_pred_results(ensemble_dict, df_weights, locations, results_dir, ensemble_name)   \n",
    "else:\n",
    "    generate_mean_ensemble_pred_results(ensemble_dict, results_dir, ensemble_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_his_stats = calculate_historical_stats(df_hosp_ex_long,states,quantiles,populations)\n",
    "first_date = pd.to_datetime('2024-11-23', format=\"%Y-%m-%d\")\n",
    "last_date = pd.to_datetime('2025-05-31', format=\"%Y-%m-%d\")\n",
    "min_peak_date = None #pd.Timestamp(ref_date) + timedelta(weeks=1)\n",
    "df_pred_peak = generate_peak_week_pred(df_his_stats, df_hosp, locations, ref_date, \n",
    "                                       first_date, last_date,min_peak_date,\n",
    "                                       kde_bandwith=0.333, plot_peak_week_prob=False)\n",
    "df_pred_peak.to_csv(\"{}/_peak_pred/{}-CU-{}.csv\".format(results_dir,format(ref_date,'%Y-%m-%d'),'peak_pred'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

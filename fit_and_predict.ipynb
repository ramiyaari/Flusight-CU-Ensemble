{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta, datetime\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiyear = 2024\n",
    "epiweek = 46 \n",
    "ref_date = epiweek_to_dates(epiyear, epiweek).enddate() #Saturday at the end of epiweek\n",
    "\n",
    "data_dir = '../../data2025/'\n",
    "results_dir = '../../results2025/'\n",
    "figures_dir = '../../figures2025/' \n",
    "\n",
    "locations_fname = data_dir +\"locations.csv\"\n",
    "locations = pd.read_csv(locations_fname)\n",
    "loc_name2abbr = dict(zip(locations['location_name'], locations['abbreviation']))\n",
    "locations = locations.set_index('abbreviation')\n",
    "states = locations.index.values\n",
    "# states = np.array([\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DE\", \"DC\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \n",
    "#           \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \n",
    "#           \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"PR\", \"US\"])\n",
    "num_states = len(states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_format = True\n",
    "download_hosp=False\n",
    "df_hosp = read_hosp_incidence_data(data_dir, epiyear, epiweek, states, \n",
    "                                   new_format=new_format, download=download_hosp, plot=False)\n",
    "\n",
    "df_ili = read_ili_incidence_data(data_dir, epiyear, epiweek, states, df_hosp, \n",
    "                                 smooth=False, scale=True, plot=False)\n",
    "\n",
    "plot_hosp_with_ili = False\n",
    "if(plot_hosp_with_ili):\n",
    "    fig, axs = plt.subplots(nrows=num_states, ncols=1, figsize=(7, 2 * num_states), sharex=True)\n",
    "    for i, state in enumerate(states):\n",
    "        ax = axs[i] if num_states > 1 else axs  # Handle single subplot case\n",
    "        ax.plot(df_hosp['date'], df_hosp[state], label='Hospitalizations', color='blue')\n",
    "        ax.plot(df_ili['date'], df_ili[state], label='Scaled ILI', color='red')\n",
    "        ax.set_title(f\"{state} - Hospitalizations vs. ILI (scaled)\")\n",
    "        ax.set_ylabel(\"Cases\")\n",
    "        ax.legend()\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_epiyear = 2022\n",
    "switch_epiweek = 26\n",
    "switch_date = pd.to_datetime(epiweek_to_dates(switch_epiyear, switch_epiweek).enddate())\n",
    "\n",
    "df1 = df_ili[df_ili.date < switch_date]\n",
    "df2 = df_hosp[(df_hosp.date >= switch_date)]\n",
    "df_hosp_ex = pd.concat([df1, df2]).reset_index()\n",
    "df_hosp_ex_long = pd.melt(df_hosp_ex,id_vars=['date','year','week'],value_vars=df_hosp_ex.columns[3:],var_name='state',value_name='cases')\n",
    "plot_hosp_ex = False\n",
    "if(plot_hosp_ex):\n",
    "    g = sns.FacetGrid(df_hosp_ex_long, col=\"state\", col_wrap=5, hue=\"state\", sharey=False, sharex=True, height=3, aspect=1.33)\n",
    "    g.map(sns.lineplot, \"date\", \"cases\")\n",
    "    [plt.setp(ax.get_xticklabels(), rotation=90) for ax in g.axes.flat]\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "alpha_vals = [0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 1]\n",
    "quantiles = np.append(np.append([0.01,0.025],np.arange(0.05,0.95+0.05,0.050)),[0.975,0.99])\n",
    "weeks_to_predict = 4\n",
    "\n",
    "past_weeks = 0 # Set this to produce past weeks forecasts\n",
    "ref_dates = [pd.Timestamp(ref_date) + timedelta(weeks=w) for w in range(-past_weeks,1)]\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(230098)\n",
    "torch.manual_seed(42095703)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "model_list_local, model_list_global = get_forecasting_models(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_lab_col = 'percent_positive'\n",
    "df_lab = read_lab_selected_data(data_dir, epiyear, epiweek, states, loc_name2abbr, sel_lab_col, plot=False)\n",
    "#add missing past values\n",
    "missing_dates = df_hosp_ex[~df_hosp_ex['date'].isin(df_lab['date'])]\n",
    "missing_dates_only = missing_dates[['date']].copy()\n",
    "for col in df_lab.columns:\n",
    "    if col != 'date':\n",
    "        missing_dates_only[col] = pd.NA\n",
    "df_lab = pd.concat([df_lab, missing_dates_only], ignore_index=True)\n",
    "df_lab = df_lab.sort_values(by='date').reset_index(drop=True)\n",
    "#add some future values\n",
    "for i in range(1,5):\n",
    "    next = pd.Timestamp(epiweek_to_dates(epiyear, epiweek+i).enddate())\n",
    "    next_last_year = pd.Timestamp(epiweek_to_dates(epiyear-1, epiweek+i).enddate())\n",
    "    next_last_year_vals = df_lab[df_lab['date']==next_last_year].values\n",
    "    df_lab.loc[len(df_lab)] = [next] + next_last_year_vals[0,1:].tolist()\n",
    "\n",
    "#Set to 0 values for states with missing lab for now\n",
    "df_lab['RI'] = 0 #pd.NA\n",
    "df_lab['PR'] = 0 #pd.NA\n",
    "df_lab['DC'] = 0 #pd.NA\n",
    "df_lab['NJ'] = 0 #pd.NA\n",
    "df_lab['NH'] = 0 #pd.NA\n",
    "df_lab['NV'] = 0 #pd.NA\n",
    "df_lab['AK'] = 0 #pd.NA\n",
    "df_lab['DE'] = 0 #pd.NA\n",
    "df_lab['UT'] = 0 #pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_desc in model_list_local:\n",
    "    print(\"-----------Model: {}-----------\".format(model_desc))\n",
    "    model = model_list_local[model_desc]\n",
    "    for ref_date1 in ref_dates:\n",
    "        pred_start_date = ref_date1 \n",
    "        model = model.untrained_model()\n",
    "        pred = fit_and_predict_univariate(df_hosp_ex, states, model, model_desc, \n",
    "                                          pred_start_date, weeks_to_predict, num_samples, \n",
    "                                          fit_single_model=False, #fit one model to all states or not\n",
    "                                          df_past_covar=df_lab, df_future_covar=None)\n",
    "        dat_hosp_changerate_ref = df_hosp_ex[df_hosp_ex.date==ref_date1-timedelta(weeks=1)]\n",
    "        save_pred_results_to_file(pred, ref_date1, model_desc, locations, quantiles, dat_hosp_changerate_ref, results_dir)\n",
    "\n",
    "for model_desc in model_list_global:\n",
    "    print(\"-----------Model: {}-----------\".format(model_desc))\n",
    "    model = model_list_global[model_desc]\n",
    "    for ref_date1 in ref_dates:\n",
    "        pred_start_date = ref_date1 \n",
    "        model = model.untrained_model()\n",
    "        pred = fit_and_predict_multivariate(df_hosp_ex, states, model, model_desc, \n",
    "                                            pred_start_date, weeks_to_predict, num_samples,\n",
    "                                            df_past_covar=df_lab, df_future_covar=None)\n",
    "        dat_hosp_changerate_ref = df_hosp_ex[df_hosp_ex.date==ref_date1-timedelta(weeks=1)]\n",
    "        save_pred_results_to_file(pred, ref_date1, model_desc, locations, quantiles, dat_hosp_changerate_ref, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_and_plot_models(models, plot=True):\n",
    "    df_metrics_all = pd.DataFrame({\n",
    "        'location': pd.Series(dtype='str'),\n",
    "        'model': pd.Series(dtype='str'),\n",
    "        'horizon': pd.Series(dtype='int'),\n",
    "        'target_date': pd.Series(dtype='str'),\n",
    "        'metric': pd.Series(dtype='str'),\n",
    "        'value': pd.Series(dtype='float')\n",
    "    })\n",
    "    for model in models:\n",
    "        print(\"-----------Loading model: {}-----------\".format(model))\n",
    "        df_results = load_pred_result_files(results_dir, model, locations)\n",
    "        print(\"-----------Calculating metrics for model: {}-----------\".format(model))\n",
    "        for loc_abbr in locations.index:\n",
    "            df_metrics = calc_and_plot_pred_results_fit(df_results, df_hosp_ex, locations, loc_abbr,  \n",
    "                                                        alpha_vals, figures_dir, model, plot=plot)\n",
    "            df_metrics_all = pd.concat([df_metrics_all, df_metrics], ignore_index=True) \n",
    "    return df_metrics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = list(model_list_local.keys()) + list(model_list_global.keys()) + ['SEIRS']\n",
    "\n",
    "ensemble_dict = {}\n",
    "# load models predictions\n",
    "for model in ensemble_models:\n",
    "    print(\"-----------Loading model: {}-----------\".format(model))\n",
    "    df_results = load_pred_result_files(results_dir, model, locations)\n",
    "    ensemble_dict[model] = df_results\n",
    "\n",
    "weights_metric = 'wis'\n",
    "weights_win = 4\n",
    "df_metrics = calc_and_plot_models(ensemble_models,plot=False)\n",
    "df_weights = generate_pred_weights(ensemble_dict, df_metrics, weights_metric, weights_win, locations)\n",
    "wis_ensemble_name = 'CU_Ensemble'\n",
    "print(\"-----------Generating weighted ensemble: {}-----------\".format(wis_ensemble_name))\n",
    "generate_weighted_pred_results(ensemble_dict, df_weights, locations, results_dir, wis_ensemble_name)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_his_stats = calculate_historical_stats(df_hosp_ex_long,states,quantiles)\n",
    "\n",
    "last_date = pd.to_datetime('2025-05-31', format=\"%Y-%m-%d\")\n",
    "df_pred_peak = generate_peak_week_pred(df_his_stats, locations, ref_date, last_date,\n",
    "                                       kde_bandwith=0.5, plot_peak_week_prob=False)\n",
    "\n",
    "save_pred_peak_with_model_pred(df_pred_peak, results_dir, wis_ensemble_name, locations, ref_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
